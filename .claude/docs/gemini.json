{
  "api_name": "Google Gemini API",
  "description": "The Gemini API provides access to Google's advanced AI models for text, image, speech, and video generation and understanding, enabling developers to build innovative applications.",
  "base_url": "https://generativelanguage.googleapis.com",
  "authentication": {
    "type": "API Key",
    "header": "x-goog-api-key",
    "description": "API key obtained from Google AI Studio"
  },
  "models": {
    "recommended": "gemini-2.5-flash",
    "alternatives": [
      "gemini-1.5-flash",
      "gemini-2.5-flash-native-audio-preview-09-2025",
      "gemini-2.5-computer-use-preview-10-2025"
    ]
  },
  "key_features": {
    "function_calling": {
      "description": "Enable the model to call user-defined functions based on natural language prompts",
      "supported": true,
      "modes": [
        "any",
        "auto",
        "none"
      ]
    },
    "web_search_integration": {
      "description": "Dynamic Google Search retrieval tool for up-to-date information",
      "supported": true,
      "tool_name": "google_search_retrieval",
      "dynamic_threshold": "0.7 (only searches if confidence > 70%)"
    },
    "streaming": {
      "description": "Real-time streaming of generated content",
      "supported": true,
      "methods": [
        "generate_content_stream",
        "generateContentStream"
      ]
    },
    "structured_output": {
      "description": "Generate JSON output conforming to a schema",
      "supported": true,
      "mime_type": "application/json",
      "schema_formats": [
        "JSON Schema",
        "Pydantic (Python)",
        "Zod (JavaScript)"
      ]
    },
    "multimodal": {
      "description": "Process text, images, audio, and video inputs",
      "supported": true
    },
    "live_api": {
      "description": "WebSocket-based real-time bidirectional communication",
      "supported": true,
      "protocol": "WebSocket"
    }
  },
  "endpoints": {
    "generate_content": {
      "method": "POST",
      "path": "/v1beta/models/{model}:generateContent",
      "description": "Generates content using Gemini models with support for function declarations",
      "parameters": {
        "path": {
          "model": {
            "type": "string",
            "required": true,
            "example": "gemini-2.5-flash"
          }
        },
        "headers": {
          "x-goog-api-key": {
            "type": "string",
            "required": true,
            "description": "Your Gemini API key"
          },
          "Content-Type": {
            "type": "string",
            "required": true,
            "value": "application/json"
          }
        },
        "body": {
          "contents": {
            "type": "array",
            "required": true,
            "description": "Array of content objects with role and parts"
          },
          "tools": {
            "type": "array",
            "required": false,
            "description": "Array of tool objects containing function declarations"
          },
          "config": {
            "type": "object",
            "required": false,
            "description": "Configuration for generation including response format"
          }
        }
      },
      "response": {
        "candidates": {
          "type": "array",
          "description": "Array of generated content candidates"
        },
        "functionCall": {
          "type": "object",
          "description": "Function call with name and extracted arguments (if applicable)"
        },
        "text": {
          "type": "string",
          "description": "Generated text response (if no function call)"
        }
      }
    }
  },
  "rate_limits": {
    "note": "Rate limits vary by model and pricing tier. Check official documentation for current limits."
  },
  "pricing": {
    "note": "Pricing varies by model, input/output tokens, and features used. Check official documentation for current pricing."
  },
  "code_examples": {
    "function_calling_python": {
      "description": "Call Gemini API with function declarations to extract structured data",
      "language": "python",
      "code": "from google import genai\nfrom google.genai import types\n\nclient = genai.Client()\nconfig = types.GenerateContentConfig(\n    tools=[get_weather_forecast, set_thermostat_temperature]\n)\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-flash\",\n    contents=\"If it's warmer than 20°C in London, set the thermostat to 20°C, otherwise set it to 18°C.\",\n    config=config,\n)\n\nprint(response.text)"
    },
    "function_calling_javascript": {
      "description": "Orchestrate model-driven function calls in a loop",
      "language": "javascript",
      "code": "import { GoogleGenAI, Type } from '@google/genai';\n\nconst ai = new GoogleGenAI({});\n\nconst tools = [\n  {\n    functionDeclarations: [\n      {\n        name: 'get_weather_forecast',\n        description: 'Gets the current weather temperature for a given location.',\n        parameters: {\n          type: Type.OBJECT,\n          properties: {\n            location: { type: Type.STRING }\n          },\n          required: ['location']\n        }\n      }\n    ]\n  }\n];\n\nlet contents = [\n  {\n    role: 'user',\n    parts: [{ text: 'What is the weather in London?' }]\n  }\n];\n\nwhile (true) {\n  const result = await ai.models.generateContent({\n    model: 'gemini-2.5-flash',\n    contents,\n    config: { tools }\n  });\n\n  if (result.functionCalls && result.functionCalls.length > 0) {\n    const functionCall = result.functionCalls[0];\n    const toolResponse = toolFunctions[functionCall.name](functionCall.args);\n    \n    contents.push({\n      role: 'model',\n      parts: [{ functionCall: functionCall }]\n    });\n    contents.push({\n      role: 'user',\n      parts: [{\n        functionResponse: {\n          name: functionCall.name,\n          response: { result: toolResponse }\n        }\n      }]\n    });\n  } else {\n    console.log(result.text);\n    break;\n  }\n}"
    },
    "google_search_retrieval_python": {
      "description": "Configure dynamic Google Search retrieval for fact-checking",
      "language": "python",
      "code": "import os\nfrom google import genai\nfrom google.genai import types\n\nclient = genai.Client()\n\nretrieval_tool = types.Tool(\n    google_search_retrieval=types.GoogleSearchRetrieval(\n        dynamic_retrieval_config=types.DynamicRetrievalConfig(\n            mode=types.DynamicRetrievalConfigMode.MODE_DYNAMIC,\n            dynamic_threshold=0.7  # Only search if confidence > 70%\n        )\n    )\n)\n\nconfig = types.GenerateContentConfig(\n    tools=[retrieval_tool]\n)\n\nresponse = client.models.generate_content(\n    model='gemini-1.5-flash',\n    contents=\"Who won the euro 2024?\",\n    config=config,\n)\nprint(response.text)\nif not response.candidates[0].grounding_metadata:\n    print(\"\\nModel answered from its own knowledge.\")"
    },
    "google_search_retrieval_javascript": {
      "description": "Enable Google Search in JavaScript SDK",
      "language": "javascript",
      "code": "import { GoogleGenAI, DynamicRetrievalConfigMode } from '@google/genai';\n\nconst ai = new GoogleGenAI({});\n\nconst retrievalTool = {\n  googleSearchRetrieval: {\n    dynamicRetrievalConfig: {\n      mode: DynamicRetrievalConfigMode.MODE_DYNAMIC,\n      dynamicThreshold: 0.7  // Only search if confidence > 70%\n    }\n  }\n};\n\nconst config = { tools: [retrievalTool] };\n\nconst response = await ai.models.generateContent({\n  model: 'gemini-1.5-flash',\n  contents: 'Who won the euro 2024?',\n  config\n});\n\nconsole.log(response.text);\nif (!response.candidates?.[0]?.groundingMetadata) {\n  console.log('\\nModel answered from its own knowledge.');\n}"
    },
    "streaming_python": {
      "description": "Stream generated content with structured JSON output",
      "language": "python",
      "code": "from google import genai\nfrom pydantic import BaseModel\nfrom typing import Literal\n\nclass Feedback(BaseModel):\n    sentiment: Literal[\"positive\", \"neutral\", \"negative\"]\n    summary: str\n\nclient = genai.Client()\nprompt = \"The new UI is incredibly intuitive and visually appealing. Great job.\"\n\nresponse_stream = client.models.generate_content_stream(\n    model=\"gemini-2.5-flash\",\n    contents=prompt,\n    config={\n        \"response_mime_type\": \"application/json\",\n        \"response_json_schema\": Feedback.model_json_schema(),\n    },\n)\n\nfor chunk in response_stream:\n    print(chunk.candidates[0].content.parts[0].text)"
    },
    "streaming_javascript": {
      "description": "Stream JSON output with Zod schema validation",
      "language": "javascript",
      "code": "import { GoogleGenAI } from '@google/genai';\nimport { z } from 'zod';\nimport { zodToJsonSchema } from 'zod-to-json-schema';\n\nconst ai = new GoogleGenAI({});\n\nconst feedbackSchema = z.object({\n  sentiment: z.enum(['positive', 'neutral', 'negative']),\n  summary: z.string()\n});\n\nconst stream = await ai.models.generateContentStream({\n  model: 'gemini-2.5-flash',\n  contents: 'The new UI is incredibly intuitive and visually appealing. Great job!',\n  config: {\n    responseMimeType: 'application/json',\n    responseJsonSchema: zodToJsonSchema(feedbackSchema)\n  }\n});\n\nfor await (const chunk of stream) {\n  console.log(chunk.candidates[0].content.parts[0].text);\n}"
    },
    "curl_google_search": {
      "description": "Use Google Search retrieval via curl",
      "language": "bash",
      "code": "curl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent\" \\\n  -H \"x-goog-api-key: $GEMINI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -X POST \\\n  -d '{\n    \"contents\": [\n      {\"parts\": [{\"text\": \"Who won the euro 2024?\"}]}\n    ],\n    \"tools\": [{\n      \"google_search_retrieval\": {\n        \"dynamic_retrieval_config\": {\n          \"mode\": \"MODE_DYNAMIC\",\n          \"dynamic_threshold\": 0.7\n        }\n      }\n    }]\n  }'"
    }
  },
  "critical_notes": {
    "for_realbuddy_project": {
      "web_search_verification": "Gemini supports web search via google_search_retrieval tool with dynamic threshold configuration (0.7 recommended)",
      "streaming_support": "Full streaming support via generate_content_stream (Python) and generateContentStream (JavaScript)",
      "function_calling": "Compositional function calling supported - model can chain multiple function calls",
      "structured_output": "JSON mode with schema validation available via response_mime_type and response_json_schema",
      "rate_limits": "Must verify current rate limits for production use",
      "pricing": "Must verify current pricing for production use - varies by model and features"
    }
  }
}
